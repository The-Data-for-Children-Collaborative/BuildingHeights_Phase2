#This code performs a KMeans clustering analysis on a dataset of vegetation data.
# INPUT:
# input_path : path to the file containing the analysis of the vegetation (output.csv) generated by the analyze_vhm.py description
# output_dir/ : path to the directory which will contain the results of the analysis

#OUTPUT:
# number of optimal clusters optimal_k
# silhoutte scores
# files cluster_0.csv , .... cluster_{k-1}.csv : each contains the list of files in the dataset belonging to that cluster
# summary.txt : a file containing the summary statistics of each cluster
# All the files will be saved in the folder with path output_dir
# ================================
# Here is a brief summary of what the code does:
# 1. Reads in a CSV file of vegetation data and drops unnecessary columns.
# 2. Normalizes the features in the data using the StandardScaler() function.
# 3. Selects the two features for clustering ("mean_veg_height" and "vegetation_ratio (%)").
# 4. Performs KMeans clustering on the selected features.
# 5. Uses the elbow method to determine the optimal number of clusters.
# 6. Runs KMeans clustering again with the optimal number of clusters.
# 7. Evaluates the quality of the clustering using the silhouette score.
# 8. Saves the clusters to CSV files.
# 9. Assigns the cluster labels to the original dataset and calculates the mean of each feature for each cluster.
# 10. Generates a summary file containing statistics on each cluster and saves it to the output directory.
# 11. Visualizes the clusters using a scatter plot (optional).
# 12. The code uses several functions defined in the clustering_v2_functions.py file.
# ===============================
# TO CALL THIS CODE:
# 1. make sure that clustering_v2_functions.py is include the folder
# 2. make sure you have already generated output.csv by running analyze_vhm.py before
# the file output.csv should contain filenames and have "mean_veg_height", "vegetation_ratio (%) as features
# 3. output_dir is the path to the directory
# python clustering_v2_main.py input_path output_dir/

# ==================================================================

from clustering_v2_functions import *


# 0. Set up command line argument parsing: produces input_path and output_dir
parser = argparse.ArgumentParser(description="Perform clustering analysis on input data")
parser.add_argument("input_path", help="Path to the input CSV file")
parser.add_argument("output_dir", help="Path to the output directory")   # new !!
args = parser.parse_args()

# Create output directory if it doesn't exist
output_dir = args.output_dir
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# 1. ReLoad data from CSV file as a DataFrame and remove unnecessary columns
data = pd.read_csv(args.input_path)
filenames = data["filename"]
data = data.drop(["filename", "veg_quantiles"], axis=1)

# 2. Normalize the features
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

# 3. Select the features
selected_features = ["mean_veg_height", "vegetation_ratio (%)"]
selected_data = data[selected_features]

# 4. Cluster analysis
kmeans = KMeans(n_clusters=2)
kmeans.fit(selected_data)
cluster_labels = kmeans.predict(selected_data)

# 5. Cluster evaluation
# Use the function find_elbow_point_k from the other library
optimal_k = find_elbow_point_k(selected_data, max_k=10)
print("Optimal number of clusters: ", optimal_k)

# 6. Run KMeans clustering with optimal number of clusters
kmeans = KMeans(n_clusters=optimal_k)
kmeans.fit(selected_data)
cluster_labels = kmeans.predict(selected_data)

# 7. Use the silhouette score to evaluate the quality of the clustering
silhouette_score_val = silhouette_score(selected_data, cluster_labels)
print("Silhouette score: ", silhouette_score_val)

# 8. Save clusters to CSV files
save_clusters_to_csv(filenames, cluster_labels, optimal_k, output_dir)


# 9. Interpretation
clustered_data = data.copy()
clustered_data["cluster_label"] = cluster_labels
clustered_data.groupby("cluster_label").mean()
print(clustered_data)

# 10. Generate the summary file summary.txt containing the statistics on each cluster
generate_summary_file(clustered_data, cluster_labels, output_dir)   ### added output_dir !!!!
#print("I am done with 9!")

## 11. Visualization
plt.scatter(selected_data["mean_veg_height"], selected_data["vegetation_ratio (%)"], c=cluster_labels)
plt.xlabel("Mean vegetation height")
plt.ylabel("Vegetation ratio")
plt.show()
print('Everything OK with 11.!')

print('Done! If you uncommment 11. you can also visualize the clusters ')
